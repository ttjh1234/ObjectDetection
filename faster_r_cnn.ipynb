{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "faster_r_cnn.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNt8F4/VZPo6BEZw/rLzgvv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ttjh1234/ObjectDetection/blob/main/faster_r_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Faster R_CNN"
      ],
      "metadata": {
        "id": "ujZYQ8UaefdV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 필요 라이브러리 목록"
      ],
      "metadata": {
        "id": "vp4_TqifekDA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfEzUqEzeZfm"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 패치"
      ],
      "metadata": {
        "id": "4hkRmglZeoBK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset,info=tfds.load(\"voc\",with_info=True)\n",
        "info.features['labels'].names"
      ],
      "metadata": {
        "id": "nwAOY59rem01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "voc_train,voc_test,voc_valid=dataset[\"train\"],dataset[\"test\"],dataset[\"validation\"]\n",
        "#데이터 패치 전처리 함수 \n",
        "# 이미지 500*500 크기로 resize해서 받고, label과 bbox정보들을 받음\n",
        "\n",
        "def data_preprocess(feature):\n",
        "  img=feature['image']\n",
        "  label=feature['labels']\n",
        "  bbox=feature['objects']['bbox']\n",
        "  image=tf.image.resize(img,[500,500])\n",
        "  return (image,label,bbox)\n",
        "\n",
        "voc_train2=voc_train.map(lambda feature: data_preprocess(feature))\n",
        "voc_test2=voc_test.map(lambda feature: data_preprocess(feature))\n",
        "voc_valid2=voc_valid.map(lambda feature: data_preprocess(feature))"
      ],
      "metadata": {
        "id": "MuO3-lx7eqOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils"
      ],
      "metadata": {
        "id": "F0eG4GOHesSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_anchor():\n",
        "  width,height=31,31\n",
        "  x=tf.range(width) # width는 특성맵의 width\n",
        "  y=tf.range(height) # height는 특성맵의 height\n",
        "  X,Y=tf.meshgrid(x,y)\n",
        "  center_x=tf.math.add(tf.cast(X,tf.float32),0.5)/31\n",
        "  center_y=tf.math.add(tf.cast(Y,tf.float32),0.5)/31\n",
        "  \n",
        "  scale=[128,256,512]\n",
        "  ratio1=[0.5,1,2]\n",
        "  anchor_wh=[]\n",
        "  for i in scale:\n",
        "    for r1 in ratio1:\n",
        "      w=tf.sqrt((i/500)**2/r1) # width는 원래 input image의 width : 500 가정\n",
        "      h=w*r1 # height는 원래 input image의 height : 500 가정\n",
        "      anchor_wh.append([w/2,h/2])\n",
        "\n",
        "  for i in range(len(anchor_wh)):\n",
        "    xmin=tf.clip_by_value(center_x-anchor_wh[i][0], 0, 1)\n",
        "    xmax=tf.clip_by_value(center_x+anchor_wh[i][0], 0, 1)\n",
        "    ymin=tf.clip_by_value(center_y-anchor_wh[i][1], 0, 1)\n",
        "    ymax=tf.clip_by_value(center_y+anchor_wh[i][1], 0, 1)\n",
        "    if i==0:\n",
        "      anchor_box=tf.stack([ymin,xmin,ymax,xmax],axis=2)\n",
        "      anchor_box=tf.expand_dims(anchor_box,axis=3)\n",
        "    else:\n",
        "      temp=tf.stack([ymin,xmin,ymax,xmax],axis=2)\n",
        "      temp=tf.expand_dims(temp,axis=3)\n",
        "      anchor_box=tf.concat([anchor_box,temp],axis=3)\n",
        "  \n",
        "  anchor_box=tf.transpose(anchor_box,[0,1,3,2])\n",
        "  return anchor_box"
      ],
      "metadata": {
        "id": "NTPz6MLbesIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def making_rpn_train(anchor_box,gt_box):\n",
        "  # anchor_box와 이미지 내 gt_box와의 IoU 계산\n",
        "  # IoU가 0.7 이상이면 positive sample 0.3 미만이면 negative sample\n",
        "  \n",
        "  gt_box_size=(gt_box[:,2]-gt_box[:,0])*(gt_box[:,3]-gt_box[:,1])\n",
        "  anchor_box=tf.reshape(anchor_box,[31*31*9,1,4])\n",
        "  anchor_box_size=(anchor_box[:,:,2]-anchor_box[:,:,0])*(anchor_box[:,:,3]-anchor_box[:,:,1])\n",
        "  \n",
        "  xmin=tf.math.maximum(anchor_box[:,:,1],gt_box[:,1])\n",
        "  ymin=tf.math.maximum(anchor_box[:,:,0],gt_box[:,0])\n",
        "  xmax=tf.math.minimum(anchor_box[:,:,3],gt_box[:,3])\n",
        "  ymax=tf.math.minimum(anchor_box[:,:,2],gt_box[:,2])\n",
        "\n",
        "  intersection=(xmax-xmin)*(ymax-ymin)\n",
        "  intersection2=tf.where((xmax>xmin)&(ymax>ymin),intersection,0)\n",
        "  intersection3=tf.where(intersection2>0,intersection2,0)\n",
        "\n",
        "  union=gt_box_size[tf.newaxis,:]+anchor_box_size-intersection3\n",
        "  iou=intersection3/union\n",
        "\n",
        "  # 추가로 해야 할 부분\n",
        "  # 도출된 iou값을 기준으로 index를 알아와서 positive와 negative 구분하기.\n",
        "  positive_index=tf.where(iou>=0.6)\n",
        "  iou_positive=tf.where(iou>=0.6)\n",
        "  negative_index=tf.where(iou<0.3)\n",
        "  iou_negative=tf.where(iou<0.3)\n",
        "\n",
        "  positive_ind=tf.stack([(positive_index[:,0]//9)//31,(positive_index[:,0]//9)%31,positive_index[:,0]%9,iou_positive[:,1]],axis=1)\n",
        "  negative_ind=tf.stack([(negative_index[:,0]//9)//31,(negative_index[:,0]//9)%31,negative_index[:,0]%9,iou_negative[:,1]],axis=1)\n",
        "\n",
        "  return iou,positive_ind,negative_ind"
      ],
      "metadata": {
        "id": "dOpd97uwewsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def making_valid_positive(anchor_box,gt_box):\n",
        "  gt_box_size=(gt_box[:,2]-gt_box[:,0])*(gt_box[:,3]-gt_box[:,1])\n",
        "  anchor_box=tf.reshape(anchor_box,[31*31*9,1,4])\n",
        "  anchor_box_size=(anchor_box[:,:,2]-anchor_box[:,:,0])*(anchor_box[:,:,3]-anchor_box[:,:,1])\n",
        "  print(gt_box_size.shape,anchor_box_size.shape)\n",
        "\n",
        "  xmin=tf.math.maximum(anchor_box[:,:,1],gt_box[:,1])\n",
        "  ymin=tf.math.maximum(anchor_box[:,:,0],gt_box[:,0])\n",
        "  xmax=tf.math.minimum(anchor_box[:,:,3],gt_box[:,3])\n",
        "  ymax=tf.math.minimum(anchor_box[:,:,2],gt_box[:,2])\n",
        "\n",
        "  intersection=(xmax-xmin)*(ymax-ymin)\n",
        "  intersection2=tf.where((xmax>xmin)&(ymax>ymin),intersection,0)\n",
        "  intersection2=tf.where((xmax<xmin)|(ymax<ymin),0,intersection2)\n",
        "  intersection3=tf.where(intersection2>0,intersection2,0)\n",
        "  print(intersection3.shape)\n",
        "\n",
        "  union=gt_box_size[tf.newaxis,:]+anchor_box_size-intersection3\n",
        "  print(union.shape)\n",
        "  iou=intersection3/union\n",
        "\n",
        "  # 추가로 해야 할 부분\n",
        "  # 도출된 iou값을 기준으로 index를 알아와서 positive와 negative 구분하기.\n",
        "  positive_index=tf.where(iou>=0.6)\n",
        "  iou_positive=tf.where(iou>=0.6)\n",
        "\n",
        "\n",
        "  positive_ind=tf.stack([(positive_index[:,0]//9)//31,(positive_index[:,0]//9)%31,positive_index[:,0]%9,iou_positive[:,1]],axis=1)\n",
        "  print(positive_ind.shape)\n",
        "  return positive_ind"
      ],
      "metadata": {
        "id": "kpOxngqPezBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vision_valid(image,gt_box):\n",
        "  img_rgb_copy = image.numpy().copy()/255.0\n",
        "  green_rgb = (125, 255, 51)\n",
        "  for rect in gt_box:\n",
        "\n",
        "    left = rect[1]*image.shape[1]\n",
        "    top = rect[0]*image.shape[0]\n",
        "    # rect[2], rect[3]은 너비와 높이이므로 우하단 좌표를 구하기 위해 좌상단 좌표에 각각을 더함.\n",
        "    right = rect[3]*image.shape[1]\n",
        "    bottom = rect[2]*image.shape[0]\n",
        "    \n",
        "\n",
        "    img_rgb_copy = cv2.rectangle(img_rgb_copy, (left, top), (right, bottom), color=green_rgb, thickness=1)\n",
        "\n",
        "  plt.figure(figsize=(8, 8))\n",
        "  plt.imshow(img_rgb_copy)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "yQAdu9XPe0mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def making_loss_data(y_true,y_pred,anchor):\n",
        "    w_a=anchor[:,3]-anchor[:,1]\n",
        "    h_a=anchor[:,2]-anchor[:,0]\n",
        "    t_x_star=y_true[:,1]-anchor[:,1]/w_a\n",
        "    t_x=y_pred[:,1]-anchor[:,1]/w_a\n",
        "    t_y_star=y_true[:,0]-anchor[:,0]/h_a\n",
        "    t_y=y_pred[:,0]-anchor[:,0]/h_a\n",
        "    t_w_star=tf.math.log((y_true[:,3]-y_true[:,1])/w_a)\n",
        "    t_w=tf.math.log(tf.clip_by_value((y_pred[:,3]-y_pred[:,1]),1e-4,1e+10)/w_a)\n",
        "    t_h_star=tf.math.log((y_true[:,2]-y_true[:,0])/h_a)\n",
        "    t_h=tf.math.log(tf.clip_by_value((y_pred[:,2]-y_pred[:,0]),1e-4,1e+10)/h_a)\n",
        "\n",
        "    return tf.stack([t_x_star,t_y_star,t_w_star,t_h_star],axis=1),tf.stack([t_x,t_y,t_w,t_h],axis=1)"
      ],
      "metadata": {
        "id": "RYqAFwkbe17C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def non_maximum_suppression(b_box,confidence_score):\n",
        "  #구현 예정\n",
        "  return None"
      ],
      "metadata": {
        "id": "FfLw1pjJe3UR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def patch_batch(data):\n",
        "  image=data[0]\n",
        "  gt_box=data[2]\n",
        "  p_flag=0\n",
        "  iou,positive_index,negative_index=making_rpn_train(anchor_box,gt_box)\n",
        "  if positive_index.shape[0]==0:\n",
        "      p_flag=1\n",
        "      return image,None,None,None,None,None,None,None,None, p_flag\n",
        "      \n",
        "\n",
        "  if positive_index.shape[0]<128:    \n",
        "    pindex=tf.random.shuffle(positive_index,name='positive_shuffle')\n",
        "    pdata=tf.gather_nd(anchor_box,indices=tf.unstack(pindex[:,:3]))\n",
        "    #number of positive\n",
        "    nop=positive_index.shape[0]\n",
        "  else:\n",
        "    pindex=tf.random.shuffle(positive_index,name='positive_shuffle')[:128]\n",
        "    pdata=tf.gather_nd(anchor_box,indices=tf.unstack(pindex[:,:3]))\n",
        "    nop=128\n",
        "\n",
        "  #number of negative\n",
        "  non=256-nop\n",
        "  nindex=tf.random.shuffle(negative_index,name='negative_shuffle')[:non]\n",
        "  ndata=tf.gather_nd(anchor_box,indices=tf.unstack(nindex[:,:3]))\n",
        "\n",
        "  label_list=tf.concat([tf.ones((nop,1)),tf.zeros((non,1))],axis=0)\n",
        "  anchor_list=tf.concat([pdata,ndata],axis=0)\n",
        "  gt_list=tf.concat([pindex[:,3],nindex[:,3]],axis=0)\n",
        "  tindex=tf.random.shuffle(tf.range(256),name='total_shuffle')\n",
        "\n",
        "  batch_label=tf.gather(label_list,indices=tindex)\n",
        "  batch_anchor=tf.gather(anchor_list,indices=tindex)\n",
        "  gt_list=tf.gather(gt_list,indices=tindex)\n",
        "  batch_gt=tf.gather(gt_box,indices=gt_list)\n",
        "  batch_pgt=tf.gather(gt_box,indices=pindex[:,3])\n",
        "\n",
        "  data_index=tf.concat([pindex,nindex],axis=0)\n",
        "  pred_index=tf.gather(data_index,indices=tindex)\n",
        "\n",
        "  image=tf.expand_dims(image,axis=0)\n",
        "\n",
        "  return image,batch_label,batch_anchor,batch_gt,gt_list,pred_index,pindex,batch_pgt,pdata,p_flag\n",
        "  # 추출해야할 요소 : Anchor_box의 좌표정보와 대응되는 gt_box의 좌표정보. \n",
        "  # making_rpn_train에서 iou정보를 이용해서 마지막 차원에 몇번째 gt_box와 대응되는지 알아야함."
      ],
      "metadata": {
        "id": "tdiH-IfBe4bN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RPN Network"
      ],
      "metadata": {
        "id": "vFGDvsKGe7Jj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = VGG16(include_top=False, input_shape=(500, 500, 3))\n",
        "feature_extractor = base_model.get_layer(\"block5_conv3\")\n",
        "initializers=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01, seed=None)\n",
        "output=Conv2D(512,(3,3),activation='relu',kernel_initializer=initializers,padding='same')(feature_extractor.output)\n",
        "rpn_cls_output = Conv2D(9, (1, 1), activation=\"sigmoid\",kernel_initializer=initializers, name=\"rpn_cls\")(output)\n",
        "rpn_reg_output = Conv2D(9 * 4, (1, 1), activation=\"linear\",kernel_initializer=initializers, name=\"rpn_reg\")(output)\n",
        "rpn_model = Model(inputs=base_model.input, outputs=[rpn_reg_output, rpn_cls_output])\n",
        "rpn_model.summary()"
      ],
      "metadata": {
        "id": "1NVWY71Ce5ru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Huber Loss와 동일\n",
        "class loss_bbr(keras.losses.Loss):\n",
        "  def __init__(self,threshold=1,**kwargs):\n",
        "    self.threshold=threshold\n",
        "    super().__init__(**kwargs)\n",
        "\n",
        "  def call(self, y_true,y_pred):\n",
        "    error=y_true-y_pred\n",
        "    is_small_error=tf.abs(error)<self.threshold\n",
        "    squared_loss=tf.square(error)/2\n",
        "    abs_loss=self.threshold * tf.abs(error)-self.threshold**2/2\n",
        "    return tf.where(is_small_error,squared_loss,abs_loss)\n",
        "\n",
        "  def get_config(self):\n",
        "    base_config=super().get_config()\n",
        "    return {**base_config}"
      ],
      "metadata": {
        "id": "rhXAGMAze-e6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch=30\n",
        "image_batch=1\n",
        "optimizer=tf.keras.optimizers.Adam()\n",
        "anchor_box=make_anchor()\n",
        "step=0\n",
        "loss_list=[10]\n",
        "revision_count=0\n",
        "loss_cls=tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "loss_bbr=loss_bbr()"
      ],
      "metadata": {
        "id": "8l_oarCofABw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_set=voc_valid2.take(5)"
      ],
      "metadata": {
        "id": "Sq2jKBeMfBPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epo in range(1,epoch+1):\n",
        "  print(\"Epoch {}/{}\".format(epo,epoch))\n",
        "  for data in voc_train2:\n",
        "    image,batch_label,batch_anchor,batch_gt,gt_list,pred_index,pindex,batch_pgt,pdata,flag=patch_batch(data)\n",
        "    if flag==1:\n",
        "      continue\n",
        "    step=step+1\n",
        "    if step%1000==0:\n",
        "      print(step)\n",
        "    with tf.GradientTape() as tape:\n",
        "      pred_reg,pred_obj=rpn_model(image,training=True)\n",
        "      pred_reg=tf.squeeze(pred_reg)\n",
        "      pred_reg=tf.reshape(pred_reg,(31,31,9,4))\n",
        "      pred_reg=tf.gather_nd(pred_reg,indices=pindex[:,:3])\n",
        "      pred_obj=tf.squeeze(pred_obj)\n",
        "      pred_obj=tf.gather_nd(pred_obj,indices=pred_index[:,:3])\n",
        "      pred_obj=tf.expand_dims(pred_obj,axis=1)\n",
        "      y_t,y_p=making_loss_data(batch_pgt,pred_reg,pdata)\n",
        "      objectness_loss=loss_cls(batch_label,pred_obj)\n",
        "      bounding_box_loss=loss_bbr(y_t,y_p)\n",
        "      loss=tf.add_n([objectness_loss/256]+[(bounding_box_loss*4/961)])\n",
        "    gradients=tape.gradient(loss,rpn_model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients,rpn_model.trainable_variables))\n",
        "  loss_list.append(tf.reduce_sum(loss))\n",
        "\n",
        "  for valid in valid_set:\n",
        "    valid_reg,valid_cls=rpn_model(tf.expand_dims(valid[0],axis=0),training=False)\n",
        "    print(\"GT Results\")\n",
        "    vision_valid(valid[0],valid[2])\n",
        "    print(\"Model Results\")\n",
        "    v_pind=making_valid_positive(anchor_box,valid[2])\n",
        "    if v_pind.shape[0]!=0:\n",
        "      v_pdata=tf.gather_nd(anchor_box,indices=tf.unstack(v_pind[:,:3]))\n",
        "      v_cls=tf.gather_nd(tf.reshape(valid_cls,(31,31,9,1)),indices=tf.unstack(v_pind[:,:3]))\n",
        "      proposed_box=tf.image.non_max_suppression(v_pdata,tf.reshape(v_cls,(-1)),5,iou_threshold=1.0)\n",
        "      v_pdata = tf.gather(v_pdata, proposed_box)\n",
        "      vision_valid(valid[0],v_pdata)\n",
        "    \n",
        "  if loss_list[epo]>loss_list[epo-1]:\n",
        "    revision_count=revision_count+1\n",
        "  else:\n",
        "    revision_count=0\n",
        "  \n",
        "  if revision_count>=10:\n",
        "    break\n",
        "  print(\"Loss = {}, revision_count = {}\".format(tf.reduce_sum(loss),revision_count))"
      ],
      "metadata": {
        "id": "-bv2AxpNfDQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for valid in valid_set:\n",
        "  valid_reg,valid_cls=rpn_model(tf.expand_dims(valid[0],axis=0),training=False)\n",
        "  print(\"GT Results\")\n",
        "  vision_valid(valid[0],valid[2])\n",
        "  print(\"Model Results\")\n",
        "  v_pind=making_valid_positive(anchor_box,valid[2])\n",
        "  if v_pind.shape[0]!=0:\n",
        "    print(v_pind.shape)\n",
        "    v_pdata=tf.gather_nd(anchor_box,indices=tf.unstack(v_pind[:,:3]))\n",
        "    v_cls=tf.gather_nd(tf.reshape(valid_cls,(31,31,9,1)),indices=tf.unstack(v_pind[:,:3]))\n",
        "    proposed_box=tf.image.non_max_suppression(v_pdata,tf.reshape(v_cls,(-1)),6000,iou_threshold=1.0)\n",
        "    v_pdata = tf.gather(v_pdata, proposed_box)\n",
        "    vision_valid(valid[0],v_pdata)"
      ],
      "metadata": {
        "id": "-I6jGshRfFEW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}